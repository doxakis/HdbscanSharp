Can AI make a better AI than we can?
Tried to post this to another forum yesterday but perhaps this is the most appropriate one: Today there's news about a computer that can play the strategy game GO far better than other computers can (and even human grandmasters, so far). This computer learned the game from first principles, rather than from examples of human strategy and games - it played itself nearly 5million times and it developed the best practices from that. Some folks say this is a computer learning "without using human knowledge" and others disagree, saying that human bias and knowledge is relevant in the choices that went into how to program this computer. So if I had a computer that was learning to program from first principles, could it create a second computer that could play GO from first principles, but without any of our bias? Sure sure, we're the first mover somewhere, but wouldn't that strip most of our fingerprints out of the final product? (And certainly, we could move to longer chains of AIs making other AIs until we are sufficiently removed, no?)  submitted by /u/TwinkletoesCT [link] [comments] 